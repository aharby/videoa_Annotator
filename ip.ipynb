{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('Familiar_Driver_Aggressive.xlsx',skiprows=6,engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root= Tk()\n",
    "\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "\n",
    "valuelist = list(df['Time'])\n",
    "v = StringVar()\n",
    "\n",
    "def slide(value):\n",
    "    newvalue = min(valuelist, key=lambda x:abs(x-float(value)))\n",
    "    horizontal.set(newvalue)\n",
    "    show_V_ACCEL_X= str(df[df['Time']==newvalue]['V_ACCEL_X'].values[0])\n",
    "    v.set('ACC: '+show_V_ACCEL_X)\n",
    "    \n",
    "\n",
    "\n",
    "horizontal = Scale(root, from_=0.0, to=max(valuelist), resolution=0.00001, orient=HORIZONTAL, command=slide)\n",
    "horizontal.pack()\n",
    "my_lable = Label(root, textvariable=v).pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Time']==newvalue]['MOB_Lane_Curvature'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df[df['Time']==46.7004]['V_ACCEL_X'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backend_bases import MouseButton\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.arange(0.0, 1.0, 0.01)\n",
    "s = np.sin(2 * np.pi * t)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s)\n",
    "\n",
    "\n",
    "def on_move(event):\n",
    "    # get the x and y pixel coords\n",
    "    x, y = event.x, event.y\n",
    "    if event.inaxes:\n",
    "        ax = event.inaxes  # the axes instance\n",
    "        print('data coords %f %f' % (event.xdata, event.ydata))\n",
    "\n",
    "\n",
    "def on_click(event):\n",
    "    if event.button is MouseButton.LEFT:\n",
    "        print('disconnecting callback')\n",
    "        plt.disconnect(binding_id)\n",
    "\n",
    "\n",
    "binding_id = plt.connect('motion_notify_event', on_move)\n",
    "plt.connect('button_press_event', on_click)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "global last_frame                                      #creating global              variable\n",
    "last_frame = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global last_frame2                                      #creating global      variable\n",
    "last_frame2 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def show_vid():                                        #creating a function\n",
    "    if not cap.isOpened():                             #checks for the opening of camera\n",
    "        print(\"cant open the camera\")\n",
    "        flag, frame = cap.read()\n",
    "        frame = cv2.resize(frame,(400,500))\n",
    "    if flag is None:\n",
    "        print (\"Major error!\")\n",
    "    elif flag:\n",
    "        global last_frame\n",
    "        last_frame = frame.copy()\n",
    "        global last_frame2\n",
    "        last_frame2 = frame.copy()\n",
    "\n",
    "    pic = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)     #we can change the display color of the frame gray,black&white here\n",
    "    img = Image.fromarray(pic)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image=imgtk)\n",
    "    lmain.after(10, show_vid)\n",
    "\n",
    "\n",
    "def show_vid2():\n",
    "    pic2 = cv2.cvtColor(last_frame2, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = Image.fromarray(pic2)\n",
    "    img2tk = ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.img2tk = img2tk\n",
    "    lmain2.configure(image=img2tk)\n",
    "    lmain2.after(10, show_vid2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root=tk.Tk()                                     #assigning root variable        for Tkinter as tk\n",
    "    lmain = tk.Label(master=root)\n",
    "    lmain2 = tk.Label(master=root)\n",
    "    #lmain.Frame= Frame(width=768, height=576)\n",
    "    #framex.grid(column=3,rowspan=2,padx=5, pady=5)\n",
    "    lmain.pack(side = LEFT)\n",
    "    lmain2.pack(side = RIGHT)\n",
    "    root.title(\"Fire Alarm Detector\")            #you can give any title\n",
    "    root.geometry(\"900x700+100+10\") #size of window , x-axis, yaxis\n",
    "    exitbutton = Button(root, text='Quit',fg=\"red\",command=   root.destroy).pack(side = BOTTOM,)\n",
    "    show_vid()\n",
    "    show_vid2()\n",
    "    root.mainloop()                                  #keeps the application in an infinite loop so it works continuosly\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_file1 = 'vtron\\\\unfamiliar_driver\\\\agressive\\\\360_view\\\\GS010054_0_to_60s.MP4'\n",
    "video_file2 ='vtron\\\\unfamiliar_driver\\\\agressive\\\\360_view\\\\GOPR0278_0_to_60s.MP4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.App at 0x29d8ec66190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tkinter\n",
    "import PIL.Image\n",
    "import PIL.ImageTk\n",
    "import cv2\n",
    "\n",
    "\n",
    "class App:\n",
    "    def __init__(self, window, video_source1, video_source2):\n",
    "        self.window = window\n",
    "        self.window.title(\"KEC MEDIA PLAYER\")\n",
    "        self.video_source1 = video_source1\n",
    "        self.video_source2 = video_source2\n",
    "        self.photo1 = \"\"\n",
    "        self.photo2 = \"\"\n",
    "\n",
    "        # open video source\n",
    "        self.vid1 = MyVideoCapture(self.video_source1, self.video_source2)\n",
    "\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas1 = tkinter.Canvas(window, width=500, height=500)\n",
    "        self.canvas2 = tkinter.Canvas(window, width=500, height=500)\n",
    "        self.canvas1.pack(padx=5, pady=10, side=\"left\")\n",
    "        self.canvas2.pack(padx=5, pady=60, side=\"left\")\n",
    "\n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret1, frame1, ret2, frame2 = self.vid1.get_frame\n",
    "\n",
    "        if ret1 and ret2:\n",
    "                self.photo1 = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(frame1))\n",
    "                self.photo2 = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(frame2))\n",
    "                self.canvas1.create_image(0, 0, image=self.photo1, anchor=tkinter.NW)\n",
    "                self.canvas2.create_image(0, 0, image=self.photo2, anchor=tkinter.NW)\n",
    "\n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "\n",
    "class MyVideoCapture:\n",
    "    def __init__(self, video_source1, video_source2):\n",
    "        # Open the video source\n",
    "        self.vid1 = cv2.VideoCapture(video_source1)\n",
    "        self.vid2 = cv2.VideoCapture(video_source2)\n",
    "\n",
    "        if not self.vid1.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source1)\n",
    "\n",
    "    @property\n",
    "    def get_frame(self):\n",
    "        ret1 = \"\"\n",
    "        ret2 = \"\"\n",
    "        if self.vid1.isOpened() and self.vid2.isOpened():\n",
    "            ret1, frame1 = self.vid1.read()\n",
    "            ret2, frame2 = self.vid2.read()\n",
    "            frame1 = cv2.resize(frame1, (500, 500))\n",
    "            frame2 = cv2.resize(frame2, (500, 500))\n",
    "            if ret1 and ret2:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return ret1, cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB), ret2, cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                return ret1, None, ret2, None\n",
    "        else:\n",
    "            return ret1, None, ret2, None\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid1.isOpened():\n",
    "            self.vid1.release()\n",
    "        if self.vid2.isOpened():\n",
    "            self.vid2.release()\n",
    "\n",
    "\n",
    "def callback():\n",
    "    global v1,v2\n",
    "    v1=E1.get()\n",
    "    v2=E2.get()\n",
    "    if v1 == \"\" or v2 == \"\":\n",
    "        L3.pack()\n",
    "        return\n",
    "    initial.destroy()\n",
    "\n",
    "\n",
    "v1 = \"\"\n",
    "v2 = \"\"\n",
    "\n",
    "initial = tkinter.Tk()\n",
    "initial.title(\"KEC MEDIA PLAYER\")\n",
    "L0 = tkinter.Label(initial, text=\"Enter the full path\")\n",
    "L0.pack()\n",
    "L1 = tkinter.Label(initial, text=\"Video 1\")\n",
    "L1.pack()\n",
    "E1 = tkinter.Entry(initial, bd =5)\n",
    "E1.pack()\n",
    "L2 = tkinter.Label(initial, text=\"Video 2\")\n",
    "L2.pack()\n",
    "E2 = tkinter.Entry(initial, bd =5)\n",
    "E2.pack()\n",
    "B = tkinter.Button(initial, text =\"Next\", command = callback)\n",
    "B.pack()\n",
    "L3 = tkinter.Label(initial, text=\"Enter both the names\")\n",
    "\n",
    "initial.mainloop()\n",
    "\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "App(tkinter.Tk(),v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_file1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-37f50ec87218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_file1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcap1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_file2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_file1' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(video_file1)\n",
    "cap1 = cv.VideoCapture(video_file2)\n",
    "\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error camera 1 isn't connecting\")\n",
    "if (cap1.isOpened()== False):\n",
    "    print(\"Error camera 2 isn't connecting\")\n",
    "\n",
    "while (cap.isOpened() or cap1.isOpened()):\n",
    "   ret, img = cap.read()\n",
    "   ret1, img1 = cap1.read()\n",
    "   if (ret == True):\n",
    "       cv.imshow('Video 1',img)\n",
    "       cv.imshow('Video 2',img1)\n",
    "\n",
    "   if cv.waitKey(20) and 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cap1.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\bibo\\appdata\\local\\programs\\python\\python39\\lib\\tkinter\\__init__.py\", line 1885, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"c:\\users\\bibo\\appdata\\local\\programs\\python\\python39\\lib\\tkinter\\__init__.py\", line 806, in callit\n",
      "    func(*args)\n",
      "  File \"<ipython-input-15-f80551fcbf63>\", line 335, in fetch_webcam_video\n",
      "    callback()\n",
      "  File \"<ipython-input-15-f80551fcbf63>\", line 260, in <lambda>\n",
      "    self.callback_queue.put((lambda: self.update_on_main_thread(self.current_frame, self.app_gui)))\n",
      "  File \"<ipython-input-15-f80551fcbf63>\", line 269, in update_on_main_thread\n",
      "    face = detect_face(current_frame)\n",
      "  File \"<ipython-input-15-f80551fcbf63>\", line 199, in detect_face\n",
      "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5);\n",
      "cv2.error: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-95hbg2jt\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # Application GUI\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import tkinter as tk\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "\n",
    "# I have taken a more modular approach so that UI is easy to change, update and extend. I have also developed UI in a way so that UI has no knowledge of how data is fetched or processed, it is just a UI. \n",
    "\n",
    "# ## Left Screen Views\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "class LeftView(tk.Frame):\n",
    "    def __init__(self, root):\n",
    "        #call super class (Frame) constructor\n",
    "        tk.Frame.__init__(self, root)\n",
    "        #save root layour for later references\n",
    "        self.root = root\n",
    "        #load all UI\n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        #create a output label\n",
    "        self.output_label = tk.Label(self, text=\"Webcam Output\", bg=\"black\", fg=\"white\")\n",
    "        self.output_label.pack(side=\"top\", fill=\"both\", expand=\"yes\", padx=10)\n",
    "        \n",
    "        #create label to hold image\n",
    "        self.image_label = tk.Label(self)\n",
    "        #put the image label inside left screen\n",
    "        self.image_label.pack(side=\"left\", fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        \n",
    "    def update_image(self, image):\n",
    "        #configure image_label with new image \n",
    "        self.image_label.configure(image=image)\n",
    "        #this is to avoid garbage collection, so we hold an explicit reference\n",
    "        self.image = image\n",
    "    \n",
    "\n",
    "\n",
    "# ## Right Screen Views\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "class RightView(tk.Frame):\n",
    "    def __init__(self, root):\n",
    "        #call super class (Frame) constructor\n",
    "        tk.Frame.__init__(self, root)\n",
    "        #save root layour for later references\n",
    "        self.root = root\n",
    "        #load all UI\n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        #create a webcam output label\n",
    "        self.output_label = tk.Label(self, text=\"Face detection Output\", bg=\"black\", fg=\"white\")\n",
    "        self.output_label.pack(side=\"top\", fill=\"both\", expand=\"yes\", padx=10)\n",
    "        \n",
    "        #create label to hold image\n",
    "        self.image_label = tk.Label(self)\n",
    "        #put the image label inside left screen\n",
    "        self.image_label.pack(side=\"left\", fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        \n",
    "        \n",
    "    def update_image(self, image):\n",
    "        #configure image_label with new image \n",
    "        self.image_label.configure(image=image)\n",
    "        #this is to avoid garbage collection, so we hold an explicit reference\n",
    "        self.image = image\n",
    "        \n",
    "\n",
    "\n",
    "# ## All App GUI Combined\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "class AppGui:\n",
    "    def __init__(self):\n",
    "        #initialize the gui toolkit\n",
    "        self.root = tk.Tk()\n",
    "        #set the geometry of the window\n",
    "        #self.root.geometry(\"550x300+300+150\")\n",
    "        \n",
    "        #set title of window\n",
    "        self.root.title(\"Face Detection\")\n",
    "        \n",
    "        #create left screen view\n",
    "        self.left_view = LeftView(self.root)\n",
    "        self.left_view.pack(side='left')\n",
    "        \n",
    "        #create right screen view\n",
    "        self.right_view = RightView(self.root)\n",
    "        self.right_view.pack(side='right')\n",
    "        \n",
    "        #define image width/height that we will use\n",
    "        #while showing an image in webcam/neural network\n",
    "        #output window\n",
    "        self.image_width=200\n",
    "        self.image_height=200\n",
    "        \n",
    "        #define the center of the cirlce based on image dimentions\n",
    "        #this is the cirlce we will use for user focus\n",
    "        self.circle_center = (int(self.image_width/2),int(self.image_height/4))\n",
    "        #define circle radius\n",
    "        self.circle_radius = 15\n",
    "        #define circle color == red\n",
    "        self.circle_color = (255, 0, 0)\n",
    "        \n",
    "        self.is_ready = True\n",
    "        \n",
    "    def launch(self):\n",
    "        #start the gui loop to listen for events\n",
    "        self.root.mainloop()\n",
    "        \n",
    "    def process_image(self, image):\n",
    "        #resize image to desired width and height\n",
    "        #image = image.resize((self.image_width, self.image_height),Image.ANTIALIAS)\n",
    "        image = cv2.resize(image, (self.image_width, self.image_height))\n",
    "        \n",
    "        #if image is RGB (3 channels, which means webcam image) then draw a circle on it\n",
    "        #for user to focus on that circle to align face\n",
    "        #if(len(image.shape) == 3):\n",
    "        #    cv2.circle(image, self.circle_center, self.circle_radius, self.circle_color, 2)\n",
    "            \n",
    "        #convert image to PIL library format which is required for Tk toolkit\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        #convert image to Tk toolkit format\n",
    "        image = ImageTk.PhotoImage(image)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    def update_webcam_output(self, image):\n",
    "        #pre-process image to desired format, height etc.\n",
    "        image = self.process_image(image)\n",
    "\n",
    "        #pass the image to left_view to update itself\n",
    "        self.left_view.update_image(image)\n",
    "        \n",
    "    def update_neural_network_output(self, image):\n",
    "        #pre-process image to desired format, height etc.\n",
    "        image = self.process_image(image)\n",
    "        #pass the image to right_view to update itself\n",
    "        self.right_view.update_image(image)\n",
    "        \n",
    "    def update_chat_view(self, question, answer_type):\n",
    "        self.left_view.update_chat_view(question, answer_type)\n",
    "        \n",
    "    def update_emotion_state(self, emotion_state):\n",
    "        self.right_view.update_emotion_state(emotion_state)\n",
    "    \n",
    "\n",
    "\n",
    "# ## Class to Access Webcam\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "import cv2\n",
    "\n",
    "class VideoCamera:\n",
    "    def __init__(self):\n",
    "        #passing 0 to VideoCapture means fetch video from webcam\n",
    "        self.video_capture = cv2.VideoCapture(video_file1)\n",
    "                \n",
    "    #release resources like webcam\n",
    "    def __del__(self):\n",
    "        self.video_capture.release()\n",
    "        \n",
    "    def read_image(self):\n",
    "        #get a single frame of video\n",
    "        ret, frame = self.video_capture.read()\n",
    "        #return the frame to user\n",
    "        return ret, frame\n",
    "    \n",
    "    #method to release webcam manually \n",
    "    def release(self):\n",
    "        self.video_capture.release()\n",
    "\n",
    "        \n",
    "\n",
    "class VideoCamera:\n",
    "    def __init__(self):\n",
    "        #passing 0 to VideoCapture means fetch video from webcam\n",
    "        self.video_capture = cv2.VideoCapture(video_file2)\n",
    "                \n",
    "    #release resources like webcam\n",
    "    def __del__(self):\n",
    "        self.video_capture.release()\n",
    "        \n",
    "    def read_image(self):\n",
    "        #get a single frame of video\n",
    "        ret, frame = self.video_capture.read()\n",
    "        #return the frame to user\n",
    "        return ret, frame\n",
    "    \n",
    "    #method to release webcam manually \n",
    "    def release(self):\n",
    "        self.video_capture.release()        \n",
    "        \n",
    "        \n",
    "# #function to detect face using OpenCV\n",
    "# def detect_face(img):\n",
    "#     #load OpenCV face detector, I am using LBP which is fast\n",
    "#     #there is also a more accurate but slow Haar classifier\n",
    "#     face_cascade = cv2.CascadeClassifier('data/lbpcascade_frontalface.xml')\n",
    "    \n",
    "#     #img_copy = np.copy(colored_img)\n",
    "    \n",
    "#     #convert the test image to gray image as opencv face detector expects gray images\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     #let's detect multiscale (some images may be closer to camera than others) images\n",
    "#     #result is a list of faces\n",
    "#     faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5);\n",
    "    \n",
    "#     #if no faces are detected then return original img\n",
    "#     if (len(faces) == 0):\n",
    "#         return img\n",
    "    \n",
    "#     #under the assumption that there will be only one face,\n",
    "#     #extract the face area\n",
    "#     (x, y, w, h) = faces[0]\n",
    "    \n",
    "#     #return only the face part of the image\n",
    "#     return img[y:y+w, x:x+h]\n",
    "\n",
    "\n",
    "# ## Thread Class for Webcam Feed\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "class WebcamThread(threading.Thread):\n",
    "    def __init__(self, app_gui, callback_queue):\n",
    "        #call super class (Thread) constructor\n",
    "        threading.Thread.__init__(self)\n",
    "        #save reference to callback_queue\n",
    "        self.callback_queue = callback_queue\n",
    "        \n",
    "        #save left_view reference so that we can update it\n",
    "        self.app_gui = app_gui\n",
    "        \n",
    "        #set a flag to see if this thread should stop\n",
    "        self.should_stop = False\n",
    "        \n",
    "        #set a flag to return current running/stop status of thread\n",
    "        self.is_stopped = False\n",
    "        \n",
    "        #create a Video camera instance\n",
    "        self.camera = VideoCamera()\n",
    "        \n",
    "    #define thread's run method\n",
    "    def run(self):\n",
    "        #start the webcam video feed\n",
    "        while (True):\n",
    "            #check if this thread should stop\n",
    "            #if yes then break this loop\n",
    "            if (self.should_stop):\n",
    "                self.is_stopped = True\n",
    "                break\n",
    "            \n",
    "            #read a video frame\n",
    "            ret, self.current_frame = self.camera.read_image()\n",
    "\n",
    "            if(ret == False):\n",
    "                print('Video capture failed')\n",
    "                exit(-1)\n",
    "                \n",
    "            #opencv reads image in BGR color space, let's convert it \n",
    "            #to RGB space\n",
    "            self.current_frame = cv2.cvtColor(self.current_frame, cv2.COLOR_BGR2RGB)\n",
    "            #key = cv2.waitKey(10)\n",
    "            \n",
    "            if self.callback_queue.full() == False:\n",
    "                #put the update UI callback to queue so that main thread can execute it\n",
    "                self.callback_queue.put((lambda: self.update_on_main_thread(self.current_frame, self.app_gui)))\n",
    "        \n",
    "        #fetching complete, let's release camera\n",
    "        #self.camera.release()\n",
    "        \n",
    "            \n",
    "    #this method will be used as callback and executed by main thread\n",
    "    def update_on_main_thread(self, current_frame, app_gui):\n",
    "        app_gui.update_webcam_output(current_frame)\n",
    "        face = detect_face(current_frame)\n",
    "        app_gui.update_neural_network_output(face)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.camera.release()\n",
    "            \n",
    "    def release_resources(self):\n",
    "        self.camera.release()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.should_stop = True\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "# ## A GUI Wrappr (Interface) to Connect it with Data\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "class Wrapper:\n",
    "    def __init__(self):\n",
    "        self.app_gui = AppGui()\n",
    "        \n",
    "        #create a Video camera instance\n",
    "        #self.camera = VideoCamera()\n",
    "        \n",
    "        #intialize variable to hold current webcam video frame\n",
    "        self.current_frame = None\n",
    "        \n",
    "        #create a queue to fetch and execute callbacks passed \n",
    "        #from background thread\n",
    "        self.callback_queue = queue.Queue()\n",
    "        \n",
    "        #create a thread to fetch webcam feed video\n",
    "        self.webcam_thread = WebcamThread(self.app_gui, self.callback_queue)\n",
    "        \n",
    "        #save attempts made to fetch webcam video in case of failure \n",
    "        self.webcam_attempts = 0\n",
    "        \n",
    "        #register callback for being called when GUI window is closed\n",
    "        self.app_gui.root.protocol(\"WM_DELETE_WINDOW\", self.on_gui_closing)\n",
    "        \n",
    "        #start webcam\n",
    "        self.start_video()\n",
    "        \n",
    "        #start fetching video\n",
    "        self.fetch_webcam_video()\n",
    "    \n",
    "    def on_gui_closing(self):\n",
    "        self.webcam_attempts = 51\n",
    "        self.webcam_thread.stop()\n",
    "        self.webcam_thread.join()\n",
    "        self.webcam_thread.release_resources()\n",
    "        \n",
    "        self.app_gui.root.destroy()\n",
    "\n",
    "    def start_video(self):\n",
    "        self.webcam_thread.start()\n",
    "        \n",
    "    def fetch_webcam_video(self):\n",
    "            try:\n",
    "                #while True:\n",
    "                #try to get a callback put by webcam_thread\n",
    "                #if there is no callback and call_queue is empty\n",
    "                #then this function will throw a Queue.Empty exception \n",
    "                callback = self.callback_queue.get_nowait()\n",
    "                callback()\n",
    "                self.webcam_attempts = 0\n",
    "                #self.app_gui.root.update_idletasks()\n",
    "                self.app_gui.root.after(70, self.fetch_webcam_video)\n",
    "                    \n",
    "            except queue.Empty:\n",
    "                if (self.webcam_attempts <= 50):\n",
    "                    self.webcam_attempts = self.webcam_attempts + 1\n",
    "                    self.app_gui.root.after(100, self.fetch_webcam_video)\n",
    "\n",
    "    def test_gui(self):\n",
    "        #test images update\n",
    "        #read the images using OpenCV, later this will be replaced\n",
    "        #by live video feed\n",
    "        image, gray = self.read_images()\n",
    "        self.app_gui.update_webcam_output(image)\n",
    "        self.app_gui.update_neural_network_output(gray)\n",
    "        \n",
    "        #test chat view update\n",
    "        self.app_gui.update_chat_view(\"4 + 4 = ? \", \"number\")\n",
    "        \n",
    "        #test emotion state update\n",
    "        self.app_gui.update_emotion_state(\"neutral\")\n",
    "        \n",
    "    def read_images(self):\n",
    "        image = cv2.imread('data/test1.jpg')\n",
    "    \n",
    "        #conver to RGB space and to gray scale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        return image, gray\n",
    "    \n",
    "    def launch(self):\n",
    "        self.app_gui.launch()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.webcam_thread.stop()\n",
    "\n",
    "\n",
    "# ## The Launcher Code For GUI\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wrapper = Wrapper()\n",
    "    wrapper.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
